{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70805227-9079-4fe9-9bff-2a02f8c8e387",
   "metadata": {},
   "source": [
    "# Fine-tune TinyLlama-1.1B for movie review classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this workshop module, you will learn how to fine-tune a Llama-based LLM using causal language modelling so that the model learns how to perform sentiment classification of movie reviews. Your fine-tuning job will be launched using SageMaker Training which provides a serverless training environment where you do not need to manage the underlying infrastructure. You will learn how to configure a PyTorch training job using [SageMaker's PyTorch estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html), and how to leverage the [Hugging Face Optimum Neuron](https://github.com/huggingface/optimum-neuron) package to easily run the PyTorch training job with AWS Trainium accelerators via an [AWS EC2 trn1.2xlarge instance](https://aws.amazon.com/ec2/instance-types/trn1/).\n",
    "\n",
    "For this module, you will be using a custom dataset based upon the popular [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) which consists of thousands of text-based movie reviews each classified as `positive` or `negative`. Our custom dataset consists of descriptive prompts which will allow the LLM to learn how to respond to queries for movie review classification. The dataset examples look like the following:\n",
    "\n",
    "*Positive example:*\n",
    "```\n",
    "###Query: Classify the following movie review as positive or negative\n",
    "###Review: \"Tulip\" is on the \"Australian All Shorts\" video from \"Tribe First Rites\" showcasing the talents of \\\n",
    "first time directors.<br /><br />I wish more scripts had such excellent dialogue.<br /><br />I hope Rachel \\\n",
    "Griffiths has more stories to tell, she does it so well.\n",
    "###Classification: positive</s>\\n\\n\n",
    "```\n",
    "\n",
    "*Negative example:*\n",
    "```\n",
    "###Query: Classify the following movie review as positive or negative\n",
    "###Review: I only watched this film from beginning to end because I promised a friend I would. It lacks even \\\n",
    "unintentional entertainment value that many bad films have. It may be the worst film I have ever seen. I'm \\\n",
    "surprised a distributor put their name on it.\n",
    "###Classification: negative</s>\\n\\n\n",
    "```\n",
    "\n",
    "By fine-tuning the model over several hundred of these prompt examples, the model will then learn how to predict 'positive' or 'negative' when presented with queries containing new movie review content. For example, once the model has been fine-tuned you can present it with the following prompt:\n",
    "```\n",
    "###Query: Classify the following movie review as positive or negative\n",
    "###Review: This movie is very funny. Amitabh Bachan and Govinda are absolutely hilarious. Acting is good. Comedy is great. \\\n",
    "They are up to their usual thing. It would be good to see a sequel to this :)<br /><br />Watch it. Good time-pass movie\n",
    "###Classification:\n",
    "```\n",
    "and if your model is trained properly it will generate `positive` as the output.\n",
    "\n",
    "\n",
    "This movie review classification use case was selected so you can successfully fine-tune your model in a reasonably short amount of time (~12 minutes) which is appropriate for this workshop. Although this is a relatively simple use case, please bear in mind that the same techniques and components used in this module can also be applied to fine-tune LLMs for more advanced use cases such as writing poetry, summarizing documents, creating blog posts - the possibilities are endless!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866074ee-c300-4793-8e63-adbcfc314ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook uses the SageMaker Python SDK to prepare, launch, and monitor the progress of a PyTorch-based training job. Before we get started, it is important to upgrade the SageMaker SDK to ensure that you are using the latest version. Run the next two cells to upgrade the SageMaker SDK and set up your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264aae2-1f18-4b59-a92c-2f169903c202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upgrade SageMaker SDK to the latest version\n",
    "%pip install -U sagemaker -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ed574-6db5-471b-8515-c0f6189e653e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging \n",
    "sagemaker_config_logger = logging.getLogger(\"sagemaker.config\") \n",
    "sagemaker_config_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Import SageMaker SDK, setup our session\n",
    "from sagemaker import get_execution_role, Session\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sess = Session()\n",
    "default_bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193108b-25fb-4d3e-85db-c66b8c04c251",
   "metadata": {},
   "source": [
    "## Specify the Neuron deep learning container (DLC) image\n",
    "\n",
    "The SageMaker Training service uses containers to execute your training script, allowing you to fully customize your training script environment and any required dependencies. For this workshop, you will use a recent Neuron deep learning container (DLC) image which is an AWS-maintained image containing the Neuron SDK, PyTorch, and commonly used Python packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ad886-6977-4295-947b-86d4892b48bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the Neuron DLC that we will use for training\n",
    "training_image = \"763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training-neuronx:1.13.1-neuronx-py310-sdk2.15.0-ubuntu20.04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8802bc-657a-419d-b86d-eb8af5eff90e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure the PyTorch Estimator\n",
    "\n",
    "The SageMaker SDK includes a [PyTorch Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html) class which you can use to define a PyTorch training job which will be executed in the SageMaker managed environment. \n",
    "\n",
    "In the following cell, you will create a PyTorch Estimator which will run the attached `run_clm.py` training script on a trn1.2xlarge instance. The `run_clm.py` script is an Optimum Neuron example training script that can be used for causal language modelling with AWS Trainium.\n",
    "\n",
    "The PyTorch Estimator has many parameters that can be used to configure your training job. A few of the most important parameters include:\n",
    "\n",
    "- *entry_point*: refers to the name of the training script that will be executed as part of this training job\n",
    "- *source_dir*: the path to the local source code directory (relative to your notebook) that will be packaged up and included inside your training container\n",
    "- *instance_count*: defines how many EC2 instances to use for this training job\n",
    "- *instance_type*: determines which type of EC2 instance will be used for training\n",
    "- *image_uri*: defines which training DLC will be used to run the training job (see Neuron DLC, above)\n",
    "- *distribution*: determines which type of distribution to use for the training job - you will need 'torch_distributed' for this workshop\n",
    "- *environment*: provides a dictionary of environment variables which will be applied to your training environment\n",
    "- *hyperparameters*: provides a dictionary of command-line arguments to pass to your training script, ex: run_clm.py\n",
    "\n",
    "In the `hyperparameters` section, you can see the specific command-line arguments that are used to control the behavior of the `run_clm.py` training script. Notably:\n",
    "- *model_name_or_path*: specifies which model you will be fine-tuning, in this case a recent checkpoint from the TinyLlama-1.1B project\n",
    "- *dataset_name*: specifies which dataset you will use for fine-tuning, in this case our customized IMDB review prompts dataset\n",
    "- *per_device_train_batch_size*: the microbatch size to be used for fine-tuning\n",
    "- *max_steps*: the maximum number of steps of fine-tuning that we want to perform\n",
    "- *tensor_parallel_size*: the tensor parallel degree for which we want to use for training. In this case we use '2' to shard the model across the 2 NeuronCores available in the trn1.2xlarge instance\n",
    "- *gradient_accumulation_steps*: how many steps for which gradients will be accumulated between updates\n",
    "- *bf16*: request BFloat16 training\n",
    "\n",
    "The below estimator has been pre-configured for you, so you do not need to make any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28014c-4d0b-452b-9bde-44aa10e61bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the PyTorch estimator\n",
    "# Note that the hyperparameters are just command-line args passed to the run_clm.py script to control its behavior\n",
    "pt_estimator = PyTorch(\n",
    "        entry_point=\"run_clm.py\",\n",
    "        role=get_execution_role(),\n",
    "        source_dir='./',\n",
    "        instance_count=1,\n",
    "        instance_type=\"ml.trn1.2xlarge\",\n",
    "        framework_version='1.13.1',\n",
    "        py_version='py310',\n",
    "        disable_profiler=True,\n",
    "        output_path=f\"s3://{default_bucket}/reinvent2023\",\n",
    "        base_job_name=\"trn1-tinyllama\",\n",
    "        sagemaker_session=sess,\n",
    "        code_bucket=f\"s3://{default_bucket}/reinvent2023_code\",\n",
    "        checkpoint_s3_uri=f\"s3://{default_bucket}/reinvent_output\",\n",
    "        image_uri=training_image,\n",
    "        distribution={\"torch_distributed\": {\"enabled\": True} },  # Required for torchrun-based job launch\n",
    "        environment={ \"FI_EFA_FORK_SAFE\": \"1\", },\n",
    "        disable_output_compression=True,\n",
    "        hyperparameters={\n",
    "            \"model_name_or_path\": \"PY007/TinyLlama-1.1B-intermediate-step-715k-1.5T\",\n",
    "            \"dataset_name\": \"5cp/imdb_review_prompts\",\n",
    "            \"per_device_train_batch_size\": 1,\n",
    "            \"do_train\": \"\",\n",
    "            \"max_steps\": 100,\n",
    "            \"block_size\": 150,\n",
    "            \"tensor_parallel_size\": 2,\n",
    "            \"output_dir\": \"/opt/ml/model\",\n",
    "            \"gradient_accumulation_steps\": 8,\n",
    "            \"logging_steps\": 5,\n",
    "            \"bf16\": \"\",\n",
    "            \"disable_tqdm\": True\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278940b-f563-4582-9df0-bd56d9b5fd28",
   "metadata": {},
   "source": [
    "## Launch the training job\n",
    "\n",
    "Once the estimator has been created, you can then launch your training job by calling `.fit()` on the estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7829c64-0190-43c3-be1a-0ccce7d45248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call fit() on the estimator to initiate the training job\n",
    "pt_estimator.fit(wait=False, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77434b2-94d7-4256-8d0b-d5d2ddb1d5ae",
   "metadata": {},
   "source": [
    "## Monitor the training job\n",
    "\n",
    "When the training job has been launched, the SageMaker Training service will then take care of:\n",
    "- launching and configuring the requested EC2 infrastructure for your training job\n",
    "- launching the requested container image on each of the EC2 instances\n",
    "- copying your source code directory and running your training script within the container(s)\n",
    "- storing your trained model artifacts in Amazon Simple Storage Service (S3)\n",
    "- decommissioning the training infrastructure\n",
    "\n",
    "While the training job is running, the following cell will periodically check and output the job status. When you see 'Completed', you know that your training job is finished and you can proceed to the remainder of the notebook. The training job typically takes about 12 minutes to complete.\n",
    "\n",
    "If you are interested in viewing the output logs from your training job, you can view the logs by navigating to the AWS CloudWatch console, selecting `Logs -> Log Groups` in the left-hand menu, and then looking for your SageMaker training job in the list. **Note:** it will usually take 4-5 minutes before the infrastructure is running and the output logs begin to be populated in CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c223037-2f8e-4eb0-9e4b-ff4dac6ede7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Periodically check job status until it shows 'Completed' (ETA ~12 minutes)\n",
    "#  You can also monitor job status in the SageMaker console, and view the SageMaker Training job logs in the CloudWatch console\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "while (job_status := pt_estimator.jobs[-1].describe()['TrainingJobStatus']) not in ['Completed', 'Error']:\n",
    "    print(f\"{datetime.now().isoformat()} Training job status: {job_status}!\")\n",
    "    sleep(30)\n",
    "    \n",
    "print(f\"\\n{datetime.now().isoformat()} Training job status: {job_status}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c94343-b0c6-4903-82cc-c8ab2f88b26b",
   "metadata": {},
   "source": [
    "## Determine location of fine-tuned model artifacts\n",
    "\n",
    "Once the training job has completed, SageMaker will copy your fine-tuned model artifacts to a specified location in S3.\n",
    "\n",
    "In the following cell, you can see how to programmatically determine the location of your model artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213af977-8ed6-4081-af65-59c70db2dbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show where the fine-tuned model is stored - previous job must be 'Completed' before running this cell\n",
    "model_archive_path = pt_estimator.jobs[-1].describe()['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(f\"Your fine-tuned model is available here:\\n\\n{model_archive_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f529f-a548-4fbd-b160-3cab5f52c488",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Please copy the above S3 path, as it will be required in the subsequent workshop module.\n",
    "\n",
    "\n",
    "Lastly, run the following cell to list the model artifacts available in your S3 model_archive_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad8c7e-6a73-4f20-944f-ac12ef286a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the contents of the fine-tuned model path in S3\n",
    "!aws s3 ls {model_archive_path}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87e73b-baa0-451a-9d90-91b3e4c6f83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca9ffa7-a694-48c0-acde-cd468d18a448",
   "metadata": {},
   "source": [
    "Congratulations on completing the LLM fine-tuning module!\n",
    "\n",
    "In the next notebook, you will learn how to deploy your fine-tuned model in a SageMaker hosted endpoint, and leverage AWS Inferentia accelerators to perform model inference. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6715fc-4f48-450e-a63c-2a055279be36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
