{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74156eb6-9517-475f-984e-2e76d24fb281",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploy a fine-tuned TinyLlama-1.1B model for generative AI inference\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this workshop module, you will learn how to deploy LLM model to [Amazon EC2 inf2 instance](https://aws.amazon.com/ec2/instance-types/inf2/) for generative AI inference.\n",
    "You will use Amazon SageMaker with [Deep learning containers for large model inference](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-large-model-dlc.html) to deploy the model fine-tuned in the previous workshop module. Amazon SageMaker deployment provides fully managed options for deploying our models using Real Time or Batch modes. AWS Inferentia gives best cost per inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc71b2-88a2-48bc-919c-9a9f86c419ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook uses the SageMaker Python SDK to deploy a fine-tuned model using SageMaker hosting service. Before we get started, it is important to upgrade the SageMaker SDK to ensure that you are using the latest version. Run the next two cells to upgrade the SageMaker SDK and set up your session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bea784-0ea8-47dc-9010-da20fa55e4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upgrade SageMaker SDK to the latest version\n",
    "%pip install -U sagemaker -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee34f8d-2912-4097-a0ad-8161bdbaa2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging \n",
    "sagemaker_config_logger = logging.getLogger(\"sagemaker.config\") \n",
    "sagemaker_config_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Import SageMaker SDK, setup our session\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers\n",
    "\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c5599-6875-4015-a6da-c22a2184f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62083e2-b9dc-4f61-96f2-8a00056d19ce",
   "metadata": {},
   "source": [
    "## Specify the LMI container image\n",
    "\n",
    "[SageMaker LMI containers](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-dlc.html) use [DJLServing](https://github.com/deepjavalibrary/djl-serving), a model server that is integrated with the [transformers-neuronx](https://github.com/aws-neuron/transformers-neuronx) library to support tensor parallelism across NeuronCores. The DJL model server and transformers-neuronx library serve as core components of the container, which also includes the [Neuron SDK](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/). This setup facilitates the loading of models onto [AWS Inferentia2](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/inferentia2.html) accelerators, parallelizes the model across multiple [NeuronCores](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/neuron-core-v2.html#neuroncores-v2-arch), and enables serving via HTTP endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5e52d-2b6d-4e6e-b645-18c4174a8ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-neuronx\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.24.0\"\n",
    "    )\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8fc7a-1608-4fa7-9799-34d4bbdcb09d",
   "metadata": {},
   "source": [
    "## Prepare Model Serving Artifacts\n",
    "\n",
    "The LMI container supports loading models from an Amazon Simple Storage Service (Amazon S3) bucket or Hugging Face Hub. You need  parameters required in *`serving.properties`* file to load and host the model. \n",
    "\n",
    "In the following cell, you will need to update *`option.model_id`* with the S3 path you copied from the previous workshop module where fine-tuned model artifact is available. It should be something like\n",
    "```\n",
    "option.model_id=s3://sagemaker-us-west-2-xxxxxxxxxxxx/reinvent2023/trn1-tinyllama-2023-11-xx-xx-xx-xx-xxx/output/model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1159da-b8b8-4b0e-bcf3-77b092a180ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=djl_python.transformers_neuronx\n",
    "option.model_id=s3://sagemaker-us-east-2-161949406237/reinvent2023/trn1-tinyllama-2023-12-07-11-34-34-726/output/model\n",
    "option.batch_size=1\n",
    "option.neuron_optimize_level=1\n",
    "option.tensor_parallel_degree=2\n",
    "option.load_in_8bit=false\n",
    "option.n_positions=512\n",
    "option.rolling_batch=auto\n",
    "option.dtype=fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd30e5-fbd1-453a-b1c8-9b284357dca3",
   "metadata": {},
   "source": [
    "Construct the tarball containing *`serving.properties`* and upload it to an S3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd069e9d-336b-4e11-8127-75a26210eeca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir mycode\n",
    "mv serving.properties mycode/\n",
    "tar czvf mycode.tar.gz mycode/\n",
    "rm -rf mycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d6478-13c5-441a-acec-cfa07e79405e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_prefix = \"reinvent2023/large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mycode.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"Code uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df241f7-f8f3-4057-9c97-b8898371363d",
   "metadata": {},
   "source": [
    "## Create SageMaker Endpoint\n",
    "Next, we create the SageMaker endpoint with the model configuration defined earlier. We use the `ml.inf2.xlarge` instance containing a single Inferentia2 accelerator with 2 NeuronCores. Model deployment will usually take 4-5 minutes as model is compiled during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba6463-fe67-49ba-b38e-54f2f8927a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.inf2.xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"tinyllama-finetuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece310d1-3922-433d-a21d-9de242e29c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)\n",
    "\n",
    "model._is_compiled_model = True\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             container_startup_health_check_timeout=500,\n",
    "             volume_size=256,\n",
    "             endpoint_name=endpoint_name,\n",
    "             ModelDataDownloadTimeoutInSeconds = 1800,\n",
    "             ContainerStartupHealthCheckTimeoutInSeconds = 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61a226-3178-45a6-a2fb-9f7bec510370",
   "metadata": {},
   "source": [
    "## Inference tests\n",
    "After the SageMaker endpoint has been created, we can make real-time predictions against SageMaker endpoints using the Predictor object:\n",
    "- Create a predictor for submit inference requests and receive reponses\n",
    "- Requests and responses are in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cac86-9b46-4d78-a914-2d0c82f58ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977b17d-dabc-45ab-89e9-43621f9ac7fe",
   "metadata": {},
   "source": [
    "Lets submit an inference requests to model server and receive inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdec03-db06-4a78-9d18-b1a5b0bfe752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_text = \"I couldn't believe this was the same director as Antonia's Line.<br /><br />This film has it all, \\\n",
    "a boring plot, disjointed flashbacks, a subplot that has nothing to do with the main plot what so ever, \\\n",
    "and totally uninteresting characters.It was painful to watch. Soooo, painful.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30696aa-7472-41bd-8da8-eb17f1aa9253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"###Query: Classify the following movie review as positive or negative\\n \\\n",
    "###Review: {review_text}\\n \\\n",
    "###Classification:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cc05a-167c-43e8-9316-7d28383bb604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = predictor.predict(\n",
    "    {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\":32, \"do_sample\":\"true\"}}\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b81c30-818e-4566-ad42-68f9e75ca228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_text = \"This movie is one of my all-time favorites. I think that Sean Penn did a great job acting. \\\n",
    "It is one of the few true stories that made it to film that I really like. It is in my top 10 films of all-time. \\\n",
    "I watch it over and over and never get tired of it. Great movie!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26540db1-d60d-42c1-9c90-e2ea0d39445e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"###Query: Classify the following movie review as positive or negative\\n \\\n",
    "###Review: {review_text}\\n \\\n",
    "###Classification:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c13cb9-6d20-4e48-a14c-25717a1a307c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = predictor.predict(\n",
    "    {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\":32, \"do_sample\":\"true\"}}\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee37c4b5-8c22-42e8-8509-00c520b7cc8f",
   "metadata": {},
   "source": [
    "## Cleanup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db708703-2952-405f-8e47-c026cc055448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad8af2-1289-4b6c-ae4d-59eafa0eeb50",
   "metadata": {
    "tags": []
   },
   "source": [
    "Congratulations on completing the LLM deployment for the inference module!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d3363-d20c-4911-83dd-8d1e619024e8",
   "metadata": {},
   "source": [
    "## (Optional) Deploy original TinyLlama model from Hugging Face hub\n",
    "\n",
    "If you have spare time, you can also consider an optional step of deploying the original TinyLlama model from [Hugging Face hub](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.4) for even more fun !\n",
    "\n",
    "In this scenario, you can specify the name of the Hugging Face model using the *`model_id`* parameter to download the model directly from the Hugging Face repo. The remaining steps of the process remain the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd14a7-e172-48fb-987d-5100f1a08f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-neuronx\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.24.0\"\n",
    "    )\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec381ba-6a96-4b9e-9ee0-bdcca0fe12e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.entryPoint=djl_python.transformers_neuronx\n",
    "option.model_id=TinyLlama/TinyLlama-1.1B-Chat-v0.4\n",
    "option.batch_size=1\n",
    "option.neuron_optimize_level=1\n",
    "option.tensor_parallel_degree=2\n",
    "option.load_in_8bit=false\n",
    "option.n_positions=512\n",
    "option.rolling_batch=auto\n",
    "option.dtype=fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3517f086-9ed2-47a5-b682-5b8685dc14f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir mycode\n",
    "mv serving.properties mycode/\n",
    "tar czvf mycode.tar.gz mycode/\n",
    "rm -rf mycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbfc6e-67f0-425e-bb49-36953ae4d191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_prefix = \"reinvent2023/large-model-lmi/code\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mycode.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"Code uploaded to --- > {code_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fedb23-8016-4867-b76b-f23f6a831800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.inf2.xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"tinyllama-original-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12867b-4757-4261-a9f3-dde215c1d64d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)\n",
    "\n",
    "model._is_compiled_model = True\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             container_startup_health_check_timeout=500,\n",
    "             volume_size=256,\n",
    "             endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7f4fc-2d7d-4440-b2d0-9644a9065338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f85d5a-1df9-49bb-969a-6959c2faf37b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"How to get in a good university?\"\n",
    "formatted_prompt = (\n",
    "    f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e958823-a660-4ab4-a377-edefdd31bfa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = predictor.predict(\n",
    "    {\"inputs\": formatted_prompt, \"parameters\": {\"max_new_tokens\":512, \"do_sample\":\"true\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89868f80-0fce-43be-b7a4-ebed5e0699ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"###Query: Classify the following movie review as positive or negative\\n \\\n",
    "###Review: {review_text}\\n \\\n",
    "###Classification:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b202fa-8839-4e75-bb96-b5bc0de451e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(\n",
    "    {\"inputs\": prompt, \"parameters\": {\"max_new_tokens\":100, \"do_sample\":\"true\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d51a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.loads(result)[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84cad1-45c6-4b97-8401-5c5f63564bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
